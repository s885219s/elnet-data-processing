{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from imutils import face_utils\n",
    "import numpy as np\n",
    "import argparse\n",
    "import imutils\n",
    "import dlib\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Landmark Detection for DIRL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "shape_predictor = 'shape_predictor_68_face_landmarks.dat'\n",
    "root = 'D:/share/new_dataset/new_human_power_reorder/dirl_new_face/256x256/DIRL/'\n",
    "img_root = 'D:/share/new_dataset/new_human_power_reorder/dirl_new_face/256x256/DIRL/face_image/'\n",
    "save_folder = 'face_feature_points_dlib'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#需要先使用\"List_all_imgs_into_fileList\"產生一個以圖片資料夾為root的檔名路徑清單以便後續讀取操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor(shape_predictor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open(img_root+'fileList.txt','r') as t:\n",
    "    lines = t.read()\n",
    "    lines = lines.split('\\n')\n",
    "    lines = lines[:-1]\n",
    "    for line in lines:\n",
    "        fn = os.path.basename(line)\n",
    "        path = os.path.dirname(line)\n",
    "        output_path = os.path.join(root,save_folder,path)\n",
    "#         classify_img = os.path.join(root,'face_feature_points','dlib','image',path)\n",
    "#         classify_txt = os.path.join(root,'face_feature_points','dlib','txt',path)\n",
    "#         if not os.path.exists(classify_img):\n",
    "#             os.makedirs(classify_img)\n",
    "#         if not os.path.exists(classify_txt):\n",
    "#             os.makedirs(classify_txt)\n",
    "#         if files_path.endswith('jpg'):\n",
    "#             files_path = files_path[:-4]+'.png'\n",
    "        if not os.path.exists(output_path):\n",
    "            os.makedirs(output_path)\n",
    "        image = cv2.imread(os.path.join(img_root,line))\n",
    "        img = imutils.resize(image,width=500)\n",
    "        ratio = image.shape[1]/500\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        rects = detector(gray,1)\n",
    "        if not len(rects):\n",
    "            print('face not found')\n",
    "#             rect = dlib.rectangle(0, 0, gray.shape[1],gray.shape[0])\n",
    "            with open(os.path.join(output_path,fn[:-4]+'.txt'),'w+') as a:\n",
    "                for i in range(14):\n",
    "                    a.write(str(i//7)+','+str(i%7)+',0,0\\n')\n",
    "                cv2.imwrite(os.path.join(output_path,fn[:-4]+'.png'),image)\n",
    "            with open(os.path.join(root,save_folder,'not_found_list.txt'),'a+') as t:\n",
    "                    t.write(os.path.join(output_path,fn[:-4]+'.png')+'\\n')\n",
    "        else:\n",
    "            temp = 0\n",
    "            for r in rects:\n",
    "                if r.width() > temp:\n",
    "                    temp = r.width()\n",
    "                    rect = r\n",
    "            shape = predictor(gray, rect)\n",
    "            shape = face_utils.shape_to_np(shape) \n",
    "            pts = shape[36:48]\n",
    "            pts_copy = pts.copy()\n",
    "            pts[6],pts[9] = pts_copy[9],pts_copy[6]\n",
    "            pts[7],pts[8] = pts_copy[8],pts_copy[7]\n",
    "            pts[10],pts[11] = pts_copy[11],pts_copy[10]\n",
    "            with open(os.path.join(output_path,fn[:-4]+'.txt'),'w') as a:\n",
    "                for i,(x,y) in enumerate(pts):\n",
    "                    x = int(x*ratio+0.5)\n",
    "                    y = int(y*ratio+0.5)\n",
    "                    cv2.circle(image, (x, y), 2, (0, 0, 255), -1)\n",
    "                    a.write(str(i//6)+','+str(i%6)+','+str(x)+','+str(y)+'\\n')\n",
    "                    if i == 5:\n",
    "                        a.write('0,6,0,0\\n')\n",
    "                    if i == 11:\n",
    "                        a.write('1,6,0,0\\n')\n",
    "                cv2.imwrite(os.path.join(output_path,fn[:-4]+'.png'),image)\n",
    "        print(output_path,fn[:-4]+'.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Landmark Detection for Web Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "shape_predictor = 'shape_predictor_68_face_landmarks.dat'\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor(shape_predictor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size_list = [256,512]\n",
    "dataset_list = ['LFPW','HELEN','300W']\n",
    "for dataset in dataset_list:\n",
    "    for size in size_list:\n",
    "        root = 'D:/share/new_dataset/new_human_power_reorder/dirl_new_face/'+str(size)+'x'+str(size)+'/'\n",
    "        img_root = 'D:/share/new_dataset/new_human_power_reorder/dirl_new_face/'+str(size)+'x'+str(size)+'/'+dataset+'/'\n",
    "        save_folder = dataset + '_predict_dlib'\n",
    "        with open(img_root+'fileList.txt','r') as t:\n",
    "            lines = t.read()\n",
    "            lines = lines.split('\\n')\n",
    "            lines = lines[:-1]\n",
    "            for line in lines:\n",
    "                fn = os.path.basename(line)\n",
    "                path = os.path.dirname(line)\n",
    "                output_path = os.path.join(root,save_folder,path)\n",
    "        #         classify_img = os.path.join(root,'face_feature_points','dlib','image',path)\n",
    "        #         classify_txt = os.path.join(root,'face_feature_points','dlib','txt',path)\n",
    "        #         if not os.path.exists(classify_img):\n",
    "        #             os.makedirs(classify_img)\n",
    "        #         if not os.path.exists(classify_txt):\n",
    "        #             os.makedirs(classify_txt)\n",
    "        #         if files_path.endswith('jpg'):\n",
    "        #             files_path = files_path[:-4]+'.png'\n",
    "                if not os.path.exists(output_path):\n",
    "                    os.makedirs(output_path)\n",
    "                image = cv2.imread(os.path.join(img_root,line))\n",
    "                img = imutils.resize(image,width=500)\n",
    "                ratio = image.shape[1]/500\n",
    "                gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "                rects = detector(gray,1)\n",
    "                if not len(rects):\n",
    "                    print('face not found')\n",
    "        #             rect = dlib.rectangle(0, 0, gray.shape[1],gray.shape[0])\n",
    "                    with open(os.path.join(output_path,fn[:-4]+'.txt'),'w+') as a:\n",
    "                        for i in range(14):\n",
    "                            a.write(str(i//7)+','+str(i%7)+',0,0\\n')\n",
    "                        cv2.imwrite(os.path.join(output_path,fn[:-4]+'.png'),image)\n",
    "                    with open(os.path.join(root,save_folder,'not_found_list.txt'),'a+') as t:\n",
    "                            t.write(os.path.join(output_path,fn[:-4]+'.png')+'\\n')\n",
    "                else:\n",
    "                    temp = 0\n",
    "                    for r in rects:\n",
    "                        if r.width() > temp:\n",
    "                            temp = r.width()\n",
    "                            rect = r\n",
    "                    shape = predictor(gray, rect)\n",
    "                    shape = face_utils.shape_to_np(shape) \n",
    "                    pts = shape[36:48]\n",
    "                    pts_copy = pts.copy()\n",
    "                    pts[6],pts[9] = pts_copy[9],pts_copy[6]\n",
    "                    pts[7],pts[8] = pts_copy[8],pts_copy[7]\n",
    "                    pts[10],pts[11] = pts_copy[11],pts_copy[10]\n",
    "                    with open(os.path.join(output_path,fn[:-4]+'.txt'),'w') as a:\n",
    "                        for i,(x,y) in enumerate(pts):\n",
    "                            x = int(x*ratio+0.5)\n",
    "                            y = int(y*ratio+0.5)\n",
    "                            cv2.circle(image, (x, y), 2, (0, 0, 255), -1)\n",
    "                            a.write(str(i//6)+','+str(i%6)+','+str(x)+','+str(y)+'\\n')\n",
    "                            if i == 5:\n",
    "                                a.write('0,6,0,0\\n')\n",
    "                            if i == 11:\n",
    "                                a.write('1,6,0,0\\n')\n",
    "                        cv2.imwrite(os.path.join(output_path,fn[:-4]+'.png'),image)\n",
    "                print(output_path,fn[:-4]+'.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
